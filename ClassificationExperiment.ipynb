{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w2w/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_aus = load_svmlight_file(f='australian_scale')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_aus[0], data_aus[1], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ----------\n",
    "        turns_ : max iteration numbers\n",
    "        learning_rate_ : learning rate\n",
    "        c_ : tradeoff\n",
    "        silence_ : print process or not\n",
    "        plot_ : plot or not\n",
    "\n",
    "    Attribute:\n",
    "    ----------\n",
    "        w_ : array, shape (n_features, ), [w1, w2, ..., wn]\n",
    "        b_ : w0, bias\n",
    "\n",
    "    Data format:\n",
    "    ----------\n",
    "        y : m*1\n",
    "        x : m*n\n",
    "        w : n*1\n",
    "        b : 1*1\n",
    "    '''\n",
    "\n",
    "    def __init__(self, turns=50, learning_rate=0.01, c=0.1, silence=False, plot=True):\n",
    "        self.turns_ = turns\n",
    "        self.learning_rate_ = learning_rate\n",
    "        self.c_ = c\n",
    "        self.silence_ = silence\n",
    "        self.plot_ = plot = plot\n",
    "\n",
    "    def calc_error(self, X, y, w, b):\n",
    "        '''\n",
    "            error = 0.5||w||^2 + C* sum (max(0, 1-yi(wTxi + b)))\n",
    "        '''\n",
    "        hinge = 1 - (X.dot(w) + b)*y\n",
    "        hinge = np.array([max(0, x) for x in hinge])\n",
    "        #         print(hinge)\n",
    "        #         print('hingesum', np.sum(hinge))\n",
    "        #         print('zhengze', w**2)\n",
    "        error = 0.5 * np.sum(w ** 2) + self.c_ * np.sum(hinge)\n",
    "        return error\n",
    "\n",
    "    def gradient(self, X, y, w, b):\n",
    "        '''\n",
    "            y_ = Xw + b\n",
    "            Hinge loss = max(0, 1-yi(wTxi + b))\n",
    "            g_w = (2/N)*XT*(y_-y)\n",
    "            g_b = (2/N)*(y_-y)\n",
    "        '''\n",
    "        N = X.shape[0]\n",
    "        hinge = 1 - (X.dot(self.w_) + self.b_)*y\n",
    "        hinge_derivative_w = np.zeros([self.w_.shape[0]])\n",
    "        hinge_derivative_b = 0.0\n",
    "        for i in range(N):\n",
    "            hin = hinge[i]\n",
    "            if hin > 0:\n",
    "                derivative = -self.c_ * y[i] * X[i]\n",
    "                # 将sparse matrix转化为array\n",
    "                hinge_derivative_w += derivative.toarray()[0]\n",
    "                hinge_derivative_b -= y[i]\n",
    "        g_w = w + np.array(hinge_derivative_w)\n",
    "        g_b = hinge_derivative_b\n",
    "        w1 = w - self.learning_rate_ * g_w\n",
    "        b1 = b - self.learning_rate_ * g_b\n",
    "        return w1, b1\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "            Gradient descent\n",
    "        '''\n",
    "        n_features = X.shape[1]\n",
    "        n_targets = 1\n",
    "        self.w_ = np.zeros([n_features])\n",
    "        self.b_ = 0\n",
    "        loss_list = []\n",
    "        for i in range(self.turns_):\n",
    "            if self.silence_ == False:\n",
    "                print('Turn %d' % i)\n",
    "                print('w:', self.w_)\n",
    "                print('b:', self.b_)\n",
    "                print('Loss:', self.calc_error(X, y, self.w_, self.b_))\n",
    "                print('---------------------------')\n",
    "                loss_list.append(self.calc_error(X, y, self.w_, self.b_))\n",
    "            self.w_, self.b_ = self.gradient(X, y, self.w_, self.b_)\n",
    "        print('Iteration End')\n",
    "        print('w:', self.w_)\n",
    "        print('b:', self.b_)\n",
    "        print('Loss:', self.calc_error(X, y, self.w_, self.b_))\n",
    "        print('---------------------------')\n",
    "        if self.silence_ == False:\n",
    "            plt.plot(range(self.turns_), loss_list)\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.title('SVM')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 0\n",
      "w: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "b: 0\n",
      "Loss: 41.4\n",
      "---------------------------\n",
      "Turn 1\n",
      "w: [-0.0002      0.00347287  0.00520079  0.0045      0.00907692  0.005575\n",
      "  0.00589375  0.0294      0.02        0.0057194   0.0032      0.0023\n",
      "  0.0020851   0.0040881 ]\n",
      "b: -0.034\n",
      "Loss: 39.7439023756\n",
      "---------------------------\n",
      "Turn 2\n",
      "w: [-0.0003998   0.00694227  0.01039637  0.0089955   0.01814477  0.01114442\n",
      "  0.01178161  0.0587706   0.03998     0.01143308  0.0063968   0.0045977\n",
      "  0.00416811  0.0081721 ]\n",
      "b: -0.068\n",
      "Loss: 38.090884206\n",
      "---------------------------\n",
      "Turn 3\n",
      "w: [-0.0005994   0.0104082   0.01558676  0.0134865   0.02720355  0.01670828\n",
      "  0.01766359  0.08811183  0.05994002  0.01714105  0.0095904   0.0068931\n",
      "  0.00624905  0.01225203]\n",
      "b: -0.102\n",
      "Loss: 36.4409393353\n",
      "---------------------------\n",
      "Turn 4\n",
      "w: [-0.0007988   0.01387066  0.02077196  0.01797302  0.03625327  0.02226657\n",
      "  0.02353968  0.11742372  0.07988008  0.02284331  0.01278081  0.00918621\n",
      "  0.0083279   0.01632787]\n",
      "b: -0.136\n",
      "Loss: 34.7940616201\n",
      "---------------------------\n",
      "Turn 5\n",
      "w: [-0.000998    0.01732966  0.02595197  0.02245504  0.04529394  0.02781931\n",
      "  0.02940989  0.14670629  0.0998002   0.02853987  0.01596803  0.01147702\n",
      "  0.01040467  0.02039964]\n",
      "b: -0.17\n",
      "Loss: 33.1502449289\n",
      "---------------------------\n",
      "Turn 6\n",
      "w: [-0.001197    0.02078521  0.03112681  0.02693259  0.05432557  0.03336649\n",
      "  0.03527424  0.17595959  0.1197004   0.03423074  0.01915206  0.01376555\n",
      "  0.01247937  0.02446734]\n",
      "b: -0.204\n",
      "Loss: 31.5094831429\n",
      "---------------------------\n",
      "Turn 7\n",
      "w: [-0.00139581  0.02423729  0.03629646  0.03140566  0.06334817  0.03890812\n",
      "  0.04113271  0.20518363  0.1395807   0.03991591  0.02233291  0.01605178\n",
      "  0.01455199  0.02853096]\n",
      "b: -0.238\n",
      "Loss: 29.8717701554\n",
      "---------------------------\n",
      "Turn 8\n",
      "w: [-0.00159441  0.02768593  0.04146095  0.03587425  0.07236175  0.04444421\n",
      "  0.04698534  0.23437844  0.15944112  0.04559539  0.02551058  0.01833573\n",
      "  0.01662253  0.03259053]\n",
      "b: -0.272\n",
      "Loss: 28.2493230656\n",
      "---------------------------\n",
      "Turn 9\n",
      "w: [-0.00209282  0.03083337  0.04617149  0.03983838  0.08091247  0.04954977\n",
      "  0.05235782  0.26304407  0.17878168  0.0507692   0.02818507  0.02051739\n",
      "  0.01825101  0.03614621]\n",
      "b: -0.301\n",
      "Loss: 27.0082641864\n",
      "---------------------------\n",
      "Turn 10\n",
      "w: [-0.00069072  0.03126046  0.04646478  0.04129854  0.08650848  0.05247522\n",
      "  0.05247515  0.28618102  0.1926029   0.05043783  0.02755688  0.02179688\n",
      "  0.01536436  0.03423572]\n",
      "b: -0.275\n",
      "Loss: 26.1603576128\n",
      "---------------------------\n",
      "Turn 11\n",
      "w: [ 0.00100997  0.03123326  0.04624889  0.04255724  0.09193736  0.05534774\n",
      "  0.05192274  0.30859484  0.20571029  0.0494068   0.02662933  0.02297508\n",
      "  0.0119154   0.03162902]\n",
      "b: -0.242\n",
      "Loss: 25.3138595379\n",
      "---------------------------\n",
      "Turn 12\n",
      "w: [ 0.00240896  0.031377    0.046232    0.04381468  0.09739926  0.05829239\n",
      "  0.05166419  0.33128625  0.21910458  0.04867679  0.0260027   0.0241521\n",
      "  0.00871508  0.02932401]\n",
      "b: -0.212\n",
      "Loss: 24.4704058089\n",
      "---------------------------\n",
      "Turn 13\n",
      "w: [ 0.00400655  0.03140454  0.04602791  0.04507087  0.10273264  0.0612091\n",
      "  0.05123456  0.35375496  0.23228548  0.04774752  0.02557669  0.02522795\n",
      "  0.00539557  0.02682132]\n",
      "b: -0.18\n",
      "Loss: 23.629001932\n",
      "---------------------------\n",
      "Turn 14\n",
      "w: [ 0.00560254  0.03143206  0.04582403  0.0463258   0.10806067  0.06412289\n",
      "  0.05080536  0.3762012   0.24545319  0.04681917  0.02515112  0.02630272\n",
      "  0.00207937  0.02432113]\n",
      "b: -0.148\n",
      "Loss: 22.7897127901\n",
      "---------------------------\n",
      "Turn 15\n",
      "w: [ 0.00709694  0.03149262  0.04579177  0.04767947  0.113268    0.06705877\n",
      "  0.05048185  0.398725    0.25870774  0.04599175  0.02502597  0.02737642\n",
      " -0.00111551  0.02192517]\n",
      "b: -0.117\n",
      "Loss: 21.9535882936\n",
      "---------------------------\n",
      "Turn 16\n",
      "w: [ 0.00848984  0.03150275  0.04569884  0.04903179  0.11841627  0.06996671\n",
      "  0.05009727  0.42112628  0.27184903  0.04506516  0.02500094  0.02834904\n",
      " -0.00439719  0.0194316 ]\n",
      "b: -0.085\n",
      "Loss: 21.1193647895\n",
      "---------------------------\n",
      "Turn 17\n",
      "w: [ 0.00988135  0.03151288  0.045606    0.05038276  0.12355939  0.07287174\n",
      "  0.04971306  0.44350515  0.28497718  0.0441395   0.02497594  0.0293207\n",
      " -0.0076756   0.01694053]\n",
      "b: -0.053\n",
      "Loss: 20.2866042005\n",
      "---------------------------\n",
      "Turn 18\n",
      "w: [ 0.01127147  0.03152299  0.04551325  0.05173238  0.12869737  0.07577387\n",
      "  0.04932924  0.46586165  0.29809221  0.04321476  0.02495096  0.03029137\n",
      " -0.01095072  0.01445195]\n",
      "b: -0.021\n",
      "Loss: 19.4553726055\n",
      "---------------------------\n",
      "Turn 19\n",
      "w: [ 0.0125602   0.03161228  0.04551463  0.05318065  0.13382252  0.0786981\n",
      "  0.04903177  0.48829579  0.31129411  0.04239095  0.02482601  0.03136108\n",
      " -0.01414657  0.01206586]\n",
      "b: 0.01\n",
      "Loss: 18.6314471753\n",
      "---------------------------\n",
      "Turn 20\n",
      "w: [ 0.01374764  0.03165011  0.04547315  0.05462746  0.13884254  0.0815444\n",
      "  0.0487118   0.51060749  0.32438282  0.0416411   0.02460119  0.03242972\n",
      " -0.01723922  0.00978016]\n",
      "b: 0.04\n",
      "Loss: 17.8462135302\n",
      "---------------------------\n",
      "Turn 21\n",
      "w: [ 0.01433389  0.03149566  0.04516239  0.05597284  0.14324216  0.08383786\n",
      "  0.04820852  0.53189688  0.33645844  0.0411696   0.02397659  0.03339729\n",
      " -0.01991718  0.00789562]\n",
      "b: 0.066\n",
      "Loss: 17.1720148051\n",
      "---------------------------\n",
      "Turn 22\n",
      "w: [ 0.01471956  0.03177189  0.04522366  0.05721686  0.14654508  0.08535402\n",
      "  0.0483481   0.55176499  0.34712198  0.04109858  0.02315261  0.0343639\n",
      " -0.02197067  0.00680352]\n",
      "b: 0.084\n",
      "Loss: 16.6632436276\n",
      "---------------------------\n",
      "Turn 23\n",
      "w: [ 0.01470484  0.03225074  0.04585065  0.05845965  0.14867545  0.08609367\n",
      "  0.0493206   0.56961322  0.35577486  0.04204554  0.02272946  0.03522953\n",
      " -0.022917    0.00706757]\n",
      "b: 0.088\n",
      "Loss: 16.2880066855\n",
      "---------------------------\n",
      "Turn 24\n",
      "w: [ 0.01549013  0.03216925  0.04582676  0.05930119  0.14997293  0.08635757\n",
      "  0.04923275  0.58484361  0.36181908  0.04183633  0.02250673  0.0359943\n",
      " -0.02465908  0.00632207]\n",
      "b: 0.102\n",
      "Loss: 16.0244859511\n",
      "---------------------------\n",
      "Turn 25\n",
      "w: [ 0.01537464  0.03256274  0.04676125  0.06004189  0.1506768   0.08664621\n",
      "  0.05011632  0.59815876  0.36595726  0.04279002  0.02218422  0.03665831\n",
      " -0.02511062  0.00690168]\n",
      "b: 0.101\n",
      "Loss: 15.8417349451\n",
      "---------------------------\n",
      "Turn 26\n",
      "w: [ 0.01555927  0.0325355   0.0471916   0.06078184  0.15098767  0.08710957\n",
      "  0.05043533  0.6095606   0.3681913   0.04318006  0.02176204  0.03702165\n",
      " -0.02598631  0.00692211]\n",
      "b: 0.105\n",
      "Loss: 15.7128991472\n",
      "---------------------------\n",
      "Turn 27\n",
      "w: [ 0.01584371  0.03262284  0.04765037  0.06162106  0.15119822  0.08762246\n",
      "  0.05095693  0.61985104  0.36932311  0.0438727   0.02124027  0.03748463\n",
      " -0.02638952  0.00742805]\n",
      "b: 0.104\n",
      "Loss: 15.6082067059\n",
      "---------------------------\n",
      "Turn 28\n",
      "w: [ 0.01612787  0.03255651  0.04782058  0.06245944  0.15147009  0.08808484\n",
      "  0.05121338  0.62913119  0.36945379  0.04426913  0.02071903  0.03794714\n",
      " -0.02697073  0.00772318]\n",
      "b: 0.105\n",
      "Loss: 15.5257122673\n",
      "---------------------------\n",
      "Turn 29\n",
      "w: [ 0.01571174  0.03268951  0.0482064   0.06309698  0.15196478  0.08854675\n",
      "  0.05180757  0.63730206  0.36848434  0.04495919  0.02009831  0.0384092\n",
      " -0.02704346  0.00848863]\n",
      "b: 0.101\n",
      "Loss: 15.4555249981\n",
      "---------------------------\n",
      "Turn 30\n",
      "w: [ 0.01559603  0.03261661  0.04830909  0.06373389  0.15257435  0.0889332\n",
      "  0.05211723  0.64516476  0.36721585  0.04534856  0.01917822  0.03897079\n",
      " -0.02736812  0.00895331]\n",
      "b: 0.1\n",
      "Loss: 15.3907219782\n",
      "---------------------------\n",
      "Turn 31\n",
      "w: [ 0.01558043  0.03259693  0.04837892  0.06437015  0.15317562  0.08929427\n",
      "  0.05234238  0.6527196   0.36564864  0.04563157  0.01835904  0.03953182\n",
      " -0.02777245  0.00931766]\n",
      "b: 0.1\n",
      "Loss: 15.3300799121\n",
      "---------------------------\n",
      "Turn 32\n",
      "w: [ 0.01576485  0.03274818  0.0487939   0.06500578  0.1536686   0.08975498\n",
      "  0.0529126   0.65986688  0.36368299  0.04626653  0.01754068  0.04009228\n",
      " -0.02783798  0.0100683 ]\n",
      "b: 0.096\n",
      "Loss: 15.2732519944\n",
      "---------------------------\n",
      "Turn 33\n",
      "w: [ 0.01584908  0.03273664  0.04899329  0.06544078  0.15433801  0.09019022\n",
      "  0.05303224  0.66670701  0.3614193   0.04642474  0.01682314  0.04065219\n",
      " -0.02827784  0.01033434]\n",
      "b: 0.097\n",
      "Loss: 15.2197697423\n",
      "---------------------------\n",
      "Turn 34\n",
      "w: [ 0.01593324  0.03279178  0.04936747  0.06587534  0.15499136  0.09067503\n",
      "  0.05332486  0.6733403   0.35895789  0.04674399  0.01590632  0.04121154\n",
      " -0.02858806  0.0107918 ]\n",
      "b: 0.096\n",
      "Loss: 15.1669895593\n",
      "---------------------------\n",
      "Turn 35\n",
      "w: [ 0.0160173   0.03284687  0.04974128  0.06630946  0.15564406  0.09115936\n",
      "  0.05361718  0.67996696  0.35649893  0.04706292  0.01499041  0.04177033\n",
      " -0.02889798  0.0112488 ]\n",
      "b: 0.095\n",
      "Loss: 15.1145463517\n",
      "---------------------------\n",
      "Turn 36\n",
      "w: [ 0.01600128  0.03292545  0.05020311  0.06674315  0.15628842  0.0916682\n",
      "  0.05399869  0.68648699  0.35394243  0.04745168  0.01417542  0.04232856\n",
      " -0.02912618  0.01179595]\n",
      "b: 0.093\n",
      "Loss: 15.0631432199\n",
      "---------------------------\n",
      "Turn 37\n",
      "w: [ 0.01608528  0.03295908  0.05059305  0.06707641  0.15701675  0.09215153\n",
      "  0.05429034  0.69290051  0.35128849  0.04774005  0.01346124  0.04288623\n",
      " -0.02944215  0.01224255]\n",
      "b: 0.092\n",
      "Loss: 15.0126238213\n",
      "---------------------------\n",
      "Turn 38\n",
      "w: [ 0.0160692   0.03305834  0.05103975  0.06740933  0.15773665  0.09265938\n",
      "  0.05467468  0.69920761  0.3485372   0.04811917  0.01284778  0.04344334\n",
      " -0.02965781  0.0127887 ]\n",
      "b: 0.09\n",
      "Loss: 14.9626204595\n",
      "---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 39\n",
      "w: [ 0.01615313  0.03308056  0.05139135  0.06764192  0.15852507  0.09321672\n",
      "  0.0549639   0.7054084   0.34568866  0.04839792  0.01233493  0.0439999\n",
      " -0.02996005  0.01323431]\n",
      "b: 0.089\n",
      "Loss: 14.9143001175\n",
      "---------------------------\n",
      "Turn 40\n",
      "w: [ 0.01613698  0.03311178  0.05179857  0.06787428  0.1594127   0.0937735\n",
      "  0.05532416  0.71130299  0.34254297  0.04874057  0.0119226   0.0445559\n",
      " -0.03015519  0.01377739]\n",
      "b: 0.087\n",
      "Loss: 14.8669037448\n",
      "---------------------------\n",
      "Turn 41\n",
      "w: [ 0.01612084  0.03314296  0.05220537  0.06810641  0.16029944  0.09432973\n",
      "  0.05568407  0.71719169  0.33940043  0.04908287  0.01151068  0.04511134\n",
      " -0.03035014  0.01431993]\n",
      "b: 0.085\n",
      "Loss: 14.8196013178\n",
      "---------------------------\n",
      "Turn 42\n",
      "w: [ 0.01610472  0.03317412  0.05261178  0.0683383   0.16118529  0.0948854\n",
      "  0.05604361  0.7230745   0.33626103  0.04942483  0.01109917  0.04566623\n",
      " -0.03054489  0.01486193]\n",
      "b: 0.083\n",
      "Loss: 14.7726108139\n",
      "---------------------------\n",
      "Turn 43\n",
      "w: [ 0.01618861  0.03313584  0.05292195  0.06846996  0.16215488  0.09551551\n",
      "  0.05630367  0.72885142  0.33302477  0.04966645  0.01058807  0.04622057\n",
      " -0.03081544  0.01530339]\n",
      "b: 0.082\n",
      "Loss: 14.7262659046\n",
      "---------------------------\n",
      "Turn 44\n",
      "w: [ 0.01627242  0.03309759  0.05323181  0.06860149  0.16312349  0.096145\n",
      "  0.05656347  0.73462257  0.32979174  0.04990783  0.01007748  0.04677435\n",
      " -0.03108573  0.0157444 ]\n",
      "b: 0.081\n",
      "Loss: 14.6800134388\n",
      "---------------------------\n",
      "Turn 45\n",
      "w: [ 0.01635615  0.03305938  0.05354137  0.06873289  0.16409113  0.09677385\n",
      "  0.05682302  0.74038795  0.32656195  0.05014897  0.0095674   0.04732757\n",
      " -0.03135574  0.01618498]\n",
      "b: 0.08\n",
      "Loss: 14.6338532317\n",
      "---------------------------\n",
      "Turn 46\n",
      "w: [ 0.0164398   0.03302121  0.05385061  0.06886416  0.16505781  0.09740208\n",
      "  0.0570823   0.74614756  0.32333539  0.05038986  0.00905783  0.04788024\n",
      " -0.03162548  0.01662511]\n",
      "b: 0.079\n",
      "Loss: 14.5877850991\n",
      "---------------------------\n",
      "Turn 47\n",
      "w: [ 0.01652336  0.03298307  0.05415955  0.06899529  0.16602352  0.09802968\n",
      "  0.05734132  0.75190141  0.32011205  0.05063052  0.00854878  0.04843236\n",
      " -0.03189496  0.01706481]\n",
      "b: 0.078\n",
      "Loss: 14.5418143623\n",
      "---------------------------\n",
      "Turn 48\n",
      "w: [ 0.01650683  0.03301165  0.05454853  0.0691263   0.16698058  0.09868165\n",
      "  0.05768429  0.75754951  0.31679194  0.05095302  0.00814023  0.04898393\n",
      " -0.03208256  0.01760286]\n",
      "b: 0.076\n",
      "Loss: 14.4962364851\n",
      "---------------------------\n",
      "Turn 49\n",
      "w: [ 0.01679033  0.03287353  0.05468445  0.06925717  0.16795975  0.09935796\n",
      "  0.05781114  0.76329196  0.31357515  0.05100804  0.00783209  0.04953495\n",
      " -0.03252038  0.01784158]\n",
      "b: 0.077\n",
      "Loss: 14.4513374731\n",
      "---------------------------\n",
      "Iteration End\n",
      "w: [ 0.01697354  0.03291524  0.0550113   0.06938791  0.16891487  0.10010861\n",
      "  0.05819778  0.76872867  0.31006157  0.05132718  0.00762425  0.05008541\n",
      " -0.03272936  0.01837882]\n",
      "b: 0.075\n",
      "Loss: 14.4064919084\n",
      "---------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVAQiIgnu/wOk87PC1xhXgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdbf51452e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = SVM(turns = 50, learning_rate = 0.001, c = 0.1)\n",
    "clf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
