{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w2w/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data_aus = load_svmlight_file(f='australian_scale')\n",
    "# 分割数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_aus[0], data_aus[1], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SVM(object):\n",
    "    '''\n",
    "    Parameters:\n",
    "    ----------\n",
    "        turns_ : max iteration numbers\n",
    "        learning_rate_ : learning rate\n",
    "        c_ : tradeoff\n",
    "        silence_ : print process or not\n",
    "        plot_ : plot or not\n",
    "\n",
    "    Attribute:\n",
    "    ----------\n",
    "        w_ : array, shape (n_features, ), [w1, w2, ..., wn]\n",
    "        b_ : w0, bias\n",
    "\n",
    "    Data format:\n",
    "    ----------\n",
    "        y : m*1\n",
    "        x : m*n\n",
    "        w : n*1\n",
    "        b : 1*1\n",
    "    '''\n",
    "\n",
    "    def __init__(self, turns=50, learning_rate=0.01, c=0.1, silence=False, plot=True):\n",
    "        self.turns_ = turns\n",
    "        self.learning_rate_ = learning_rate\n",
    "        self.c_ = c\n",
    "        self.silence_ = silence\n",
    "        self.plot_ = plot = plot\n",
    "\n",
    "    def calc_error(self, X, y, w, b):\n",
    "        '''\n",
    "            error = 0.5||w||^2 + C* sum (max(0, 1-yi(wTxi + b)))\n",
    "        '''\n",
    "        hinge = 1 - (X.dot(w) + b)*y\n",
    "        hinge = np.array([max(0, x) for x in hinge])\n",
    "        error = 0.5 * np.sum(w ** 2) + self.c_ * np.sum(hinge)\n",
    "        return error\n",
    "\n",
    "    def gradient(self, X, y, w, b):\n",
    "        '''\n",
    "            y_ = Xw + b\n",
    "            Hinge loss = max(0, 1-yi(wTxi + b))\n",
    "            g_w = (2/N)*XT*(y_-y)\n",
    "            g_b = (2/N)*(y_-y)\n",
    "        '''\n",
    "        N = X.shape[0]\n",
    "        hinge = 1 - (X.dot(self.w_) + self.b_)*y\n",
    "        hinge_derivative_w = np.zeros([self.w_.shape[0]])\n",
    "        hinge_derivative_b = 0.0\n",
    "        for i in range(N):\n",
    "            hin = hinge[i]\n",
    "            if hin > 0:\n",
    "                derivative = -self.c_ * y[i] * X[i]\n",
    "                # 将sparse matrix转化为array\n",
    "                hinge_derivative_w += derivative.toarray()[0]\n",
    "                hinge_derivative_b -= y[i]\n",
    "        g_w = w + np.array(hinge_derivative_w)\n",
    "        g_b = hinge_derivative_b\n",
    "        w1 = w - self.learning_rate_ * g_w\n",
    "        b1 = b - self.learning_rate_ * g_b\n",
    "        return w1, b1\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test, y_test):\n",
    "        '''\n",
    "            Gradient descent\n",
    "        '''\n",
    "        n_features = X_train.shape[1]\n",
    "        n_targets = 1\n",
    "        self.w_ = np.zeros([n_features])\n",
    "        self.b_ = 0\n",
    "        train_loss_list = []\n",
    "        test_loss_list = []\n",
    "        for i in range(self.turns_):\n",
    "            if self.silence_ == False:\n",
    "                print('Turn %d' % i)\n",
    "                print('w:', self.w_)\n",
    "                print('b:', self.b_)\n",
    "                print('Train Loss:', self.calc_error(X_train, y_train, self.w_, self.b_))\n",
    "                print('Test Loss:', self.calc_error(X_test, y_test, self.w_, self.b_))\n",
    "                print('---------------------------')\n",
    "                train_loss_list.append(self.calc_error(X_train, y_train, self.w_, self.b_))\n",
    "                test_loss_list.append(self.calc_error(X_test, y_test, self.w_, self.b_))\n",
    "            self.w_, self.b_ = self.gradient(X_train, y_train, self.w_, self.b_)\n",
    "        print('Iteration End')\n",
    "        print('w:', self.w_)\n",
    "        print('b:', self.b_)\n",
    "        print('Train Loss:', self.calc_error(X_train, y_train, self.w_, self.b_))\n",
    "        print('Test Loss:', self.calc_error(X_test, y_test, self.w_, self.b_))\n",
    "        print('---------------------------')\n",
    "        if self.silence_ == False:\n",
    "            fig1, = plt.plot(range(self.turns_), train_loss_list)\n",
    "            fig2, = plt.plot(range(self.turns_), test_loss_list)\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend(handles=[fig1,fig2], labels=['train_loss','validate_loss'], loc='best')\n",
    "            plt.title('SVM')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 0\n",
      "w: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "b: 0\n",
      "Train Loss: 41.4\n",
      "Test Loss: 27.6\n",
      "---------------------------\n",
      "Turn 1\n",
      "w: [-0.0002      0.00347287  0.00520079  0.0045      0.00907692  0.005575\n",
      "  0.00589375  0.0294      0.02        0.0057194   0.0032      0.0023\n",
      "  0.0020851   0.0040881 ]\n",
      "b: -0.034\n",
      "Train Loss: 39.7439023756\n",
      "Test Loss: 26.4251792754\n",
      "---------------------------\n",
      "Turn 2\n",
      "w: [-0.0003998   0.00694227  0.01039637  0.0089955   0.01814477  0.01114442\n",
      "  0.01178161  0.0587706   0.03998     0.01143308  0.0063968   0.0045977\n",
      "  0.00416811  0.0081721 ]\n",
      "b: -0.068\n",
      "Train Loss: 38.090884206\n",
      "Test Loss: 25.2529295286\n",
      "---------------------------\n",
      "Turn 3\n",
      "w: [-0.0005994   0.0104082   0.01558676  0.0134865   0.02720355  0.01670828\n",
      "  0.01766359  0.08811183  0.05994002  0.01714105  0.0095904   0.0068931\n",
      "  0.00624905  0.01225203]\n",
      "b: -0.102\n",
      "Train Loss: 36.4409393353\n",
      "Test Loss: 24.0832451123\n",
      "---------------------------\n",
      "Turn 4\n",
      "w: [-0.0007988   0.01387066  0.02077196  0.01797302  0.03625327  0.02226657\n",
      "  0.02353968  0.11742372  0.07988008  0.02284331  0.01278081  0.00918621\n",
      "  0.0083279   0.01632787]\n",
      "b: -0.136\n",
      "Train Loss: 34.7940616201\n",
      "Test Loss: 22.916120391\n",
      "---------------------------\n",
      "Turn 5\n",
      "w: [-0.000998    0.01732966  0.02595197  0.02245504  0.04529394  0.02781931\n",
      "  0.02940989  0.14670629  0.0998002   0.02853987  0.01596803  0.01147702\n",
      "  0.01040467  0.02039964]\n",
      "b: -0.17\n",
      "Train Loss: 33.1502449289\n",
      "Test Loss: 21.7515497408\n",
      "---------------------------\n",
      "Turn 6\n",
      "w: [-0.001197    0.02078521  0.03112681  0.02693259  0.05432557  0.03336649\n",
      "  0.03527424  0.17595959  0.1197004   0.03423074  0.01915206  0.01376555\n",
      "  0.01247937  0.02446734]\n",
      "b: -0.204\n",
      "Train Loss: 31.5094831429\n",
      "Test Loss: 20.5895275497\n",
      "---------------------------\n",
      "Turn 7\n",
      "w: [-0.00139581  0.02423729  0.03629646  0.03140566  0.06334817  0.03890812\n",
      "  0.04113271  0.20518363  0.1395807   0.03991591  0.02233291  0.01605178\n",
      "  0.01455199  0.02853096]\n",
      "b: -0.238\n",
      "Train Loss: 29.8717701554\n",
      "Test Loss: 19.4300482175\n",
      "---------------------------\n",
      "Turn 8\n",
      "w: [-0.00159441  0.02768593  0.04146095  0.03587425  0.07236175  0.04444421\n",
      "  0.04698534  0.23437844  0.15944112  0.04559539  0.02551058  0.01833573\n",
      "  0.01662253  0.03259053]\n",
      "b: -0.272\n",
      "Train Loss: 28.2493230656\n",
      "Test Loss: 18.2805690917\n",
      "---------------------------\n",
      "Turn 9\n",
      "w: [-0.00209282  0.03083337  0.04617149  0.03983838  0.08091247  0.04954977\n",
      "  0.05235782  0.26304407  0.17878168  0.0507692   0.02818507  0.02051739\n",
      "  0.01825101  0.03614621]\n",
      "b: -0.301\n",
      "Train Loss: 27.0082641864\n",
      "Test Loss: 17.4041781272\n",
      "---------------------------\n",
      "Turn 10\n",
      "w: [-0.00069072  0.03126046  0.04646478  0.04129854  0.08650848  0.05247522\n",
      "  0.05247515  0.28618102  0.1926029   0.05043783  0.02755688  0.02179688\n",
      "  0.01536436  0.03423572]\n",
      "b: -0.275\n",
      "Train Loss: 26.1603576128\n",
      "Test Loss: 16.9252189499\n",
      "---------------------------\n",
      "Turn 11\n",
      "w: [ 0.00100997  0.03123326  0.04624889  0.04255724  0.09193736  0.05534774\n",
      "  0.05192274  0.30859484  0.20571029  0.0494068   0.02662933  0.02297508\n",
      "  0.0119154   0.03162902]\n",
      "b: -0.242\n",
      "Train Loss: 25.3138595379\n",
      "Test Loss: 16.4594688999\n",
      "---------------------------\n",
      "Turn 12\n",
      "w: [ 0.00240896  0.031377    0.046232    0.04381468  0.09739926  0.05829239\n",
      "  0.05166419  0.33128625  0.21910458  0.04867679  0.0260027   0.0241521\n",
      "  0.00871508  0.02932401]\n",
      "b: -0.212\n",
      "Train Loss: 24.4704058089\n",
      "Test Loss: 15.9912256106\n",
      "---------------------------\n",
      "Turn 13\n",
      "w: [ 0.00400655  0.03140454  0.04602791  0.04507087  0.10273264  0.0612091\n",
      "  0.05123456  0.35375496  0.23228548  0.04774752  0.02557669  0.02522795\n",
      "  0.00539557  0.02682132]\n",
      "b: -0.18\n",
      "Train Loss: 23.629001932\n",
      "Test Loss: 15.5298653698\n",
      "---------------------------\n",
      "Turn 14\n",
      "w: [ 0.00560254  0.03143206  0.04582403  0.0463258   0.10806067  0.06412289\n",
      "  0.05080536  0.3762012   0.24545319  0.04681917  0.02515112  0.02630272\n",
      "  0.00207937  0.02432113]\n",
      "b: -0.148\n",
      "Train Loss: 22.7897127901\n",
      "Test Loss: 15.070279598\n",
      "---------------------------\n",
      "Turn 15\n",
      "w: [ 0.00709694  0.03149262  0.04579177  0.04767947  0.113268    0.06705877\n",
      "  0.05048185  0.398725    0.25870774  0.04599175  0.02502597  0.02737642\n",
      " -0.00111551  0.02192517]\n",
      "b: -0.117\n",
      "Train Loss: 21.9535882936\n",
      "Test Loss: 14.6111130723\n",
      "---------------------------\n",
      "Turn 16\n",
      "w: [ 0.00848984  0.03150275  0.04569884  0.04903179  0.11841627  0.06996671\n",
      "  0.05009727  0.42112628  0.27184903  0.04506516  0.02500094  0.02834904\n",
      " -0.00439719  0.0194316 ]\n",
      "b: -0.085\n",
      "Train Loss: 21.1193647895\n",
      "Test Loss: 14.1550506891\n",
      "---------------------------\n",
      "Turn 17\n",
      "w: [ 0.00988135  0.03151288  0.045606    0.05038276  0.12355939  0.07287174\n",
      "  0.04971306  0.44350515  0.28497718  0.0441395   0.02497594  0.0293207\n",
      " -0.0076756   0.01694053]\n",
      "b: -0.053\n",
      "Train Loss: 20.2866042005\n",
      "Test Loss: 13.7005592648\n",
      "---------------------------\n",
      "Turn 18\n",
      "w: [ 0.01127147  0.03152299  0.04551325  0.05173238  0.12869737  0.07577387\n",
      "  0.04932924  0.46586165  0.29809221  0.04321476  0.02495096  0.03029137\n",
      " -0.01095072  0.01445195]\n",
      "b: -0.021\n",
      "Train Loss: 19.4553726055\n",
      "Test Loss: 13.2474067268\n",
      "---------------------------\n",
      "Turn 19\n",
      "w: [ 0.0125602   0.03161228  0.04551463  0.05318065  0.13382252  0.0786981\n",
      "  0.04903177  0.48829579  0.31129411  0.04239095  0.02482601  0.03136108\n",
      " -0.01414657  0.01206586]\n",
      "b: 0.01\n",
      "Train Loss: 18.6314471753\n",
      "Test Loss: 12.7929179059\n",
      "---------------------------\n",
      "Turn 20\n",
      "w: [ 0.01374764  0.03165011  0.04547315  0.05462746  0.13884254  0.0815444\n",
      "  0.0487118   0.51060749  0.32438282  0.0416411   0.02460119  0.03242972\n",
      " -0.01723922  0.00978016]\n",
      "b: 0.04\n",
      "Train Loss: 17.8462135302\n",
      "Test Loss: 12.3428714046\n",
      "---------------------------\n",
      "Turn 21\n",
      "w: [ 0.01433389  0.03149566  0.04516239  0.05597284  0.14324216  0.08383786\n",
      "  0.04820852  0.53189688  0.33645844  0.0411696   0.02397659  0.03339729\n",
      " -0.01991718  0.00789562]\n",
      "b: 0.066\n",
      "Train Loss: 17.1720148051\n",
      "Test Loss: 11.9469874827\n",
      "---------------------------\n",
      "Turn 22\n",
      "w: [ 0.01471956  0.03177189  0.04522366  0.05721686  0.14654508  0.08535402\n",
      "  0.0483481   0.55176499  0.34712198  0.04109858  0.02315261  0.0343639\n",
      " -0.02197067  0.00680352]\n",
      "b: 0.084\n",
      "Train Loss: 16.6632436276\n",
      "Test Loss: 11.6327490308\n",
      "---------------------------\n",
      "Turn 23\n",
      "w: [ 0.01470484  0.03225074  0.04585065  0.05845965  0.14867545  0.08609367\n",
      "  0.0493206   0.56961322  0.35577486  0.04204554  0.02272946  0.03522953\n",
      " -0.022917    0.00706757]\n",
      "b: 0.088\n",
      "Train Loss: 16.2880066855\n",
      "Test Loss: 11.4007100581\n",
      "---------------------------\n",
      "Turn 24\n",
      "w: [ 0.01549013  0.03216925  0.04582676  0.05930119  0.14997293  0.08635757\n",
      "  0.04923275  0.58484361  0.36181908  0.04183633  0.02250673  0.0359943\n",
      " -0.02465908  0.00632207]\n",
      "b: 0.102\n",
      "Train Loss: 16.0244859511\n",
      "Test Loss: 11.2602106602\n",
      "---------------------------\n",
      "Turn 25\n",
      "w: [ 0.01537464  0.03256274  0.04676125  0.06004189  0.1506768   0.08664621\n",
      "  0.05011632  0.59815876  0.36595726  0.04279002  0.02218422  0.03665831\n",
      " -0.02511062  0.00690168]\n",
      "b: 0.101\n",
      "Train Loss: 15.8417349451\n",
      "Test Loss: 11.1376811964\n",
      "---------------------------\n",
      "Turn 26\n",
      "w: [ 0.01555927  0.0325355   0.0471916   0.06078184  0.15098767  0.08710957\n",
      "  0.05043533  0.6095606   0.3681913   0.04318006  0.02176204  0.03702165\n",
      " -0.02598631  0.00692211]\n",
      "b: 0.105\n",
      "Train Loss: 15.7128991472\n",
      "Test Loss: 11.0502923923\n",
      "---------------------------\n",
      "Turn 27\n",
      "w: [ 0.01584371  0.03262284  0.04765037  0.06162106  0.15119822  0.08762246\n",
      "  0.05095693  0.61985104  0.36932311  0.0438727   0.02124027  0.03748463\n",
      " -0.02638952  0.00742805]\n",
      "b: 0.104\n",
      "Train Loss: 15.6082067059\n",
      "Test Loss: 10.9773704254\n",
      "---------------------------\n",
      "Turn 28\n",
      "w: [ 0.01612787  0.03255651  0.04782058  0.06245944  0.15147009  0.08808484\n",
      "  0.05121338  0.62913119  0.36945379  0.04426913  0.02071903  0.03794714\n",
      " -0.02697073  0.00772318]\n",
      "b: 0.105\n",
      "Train Loss: 15.5257122673\n",
      "Test Loss: 10.9185963082\n",
      "---------------------------\n",
      "Turn 29\n",
      "w: [ 0.01571174  0.03268951  0.0482064   0.06309698  0.15196478  0.08854675\n",
      "  0.05180757  0.63730206  0.36848434  0.04495919  0.02009831  0.0384092\n",
      " -0.02704346  0.00848863]\n",
      "b: 0.101\n",
      "Train Loss: 15.4555249981\n",
      "Test Loss: 10.8684452806\n",
      "---------------------------\n",
      "Turn 30\n",
      "w: [ 0.01559603  0.03261661  0.04830909  0.06373389  0.15257435  0.0889332\n",
      "  0.05211723  0.64516476  0.36721585  0.04534856  0.01917822  0.03897079\n",
      " -0.02736812  0.00895331]\n",
      "b: 0.1\n",
      "Train Loss: 15.3907219782\n",
      "Test Loss: 10.821823978\n",
      "---------------------------\n",
      "Turn 31\n",
      "w: [ 0.01558043  0.03259693  0.04837892  0.06437015  0.15317562  0.08929427\n",
      "  0.05234238  0.6527196   0.36564864  0.04563157  0.01835904  0.03953182\n",
      " -0.02777245  0.00931766]\n",
      "b: 0.1\n",
      "Train Loss: 15.3300799121\n",
      "Test Loss: 10.7801629386\n",
      "---------------------------\n",
      "Turn 32\n",
      "w: [ 0.01576485  0.03274818  0.0487939   0.06500578  0.1536686   0.08975498\n",
      "  0.0529126   0.65986688  0.36368299  0.04626653  0.01754068  0.04009228\n",
      " -0.02783798  0.0100683 ]\n",
      "b: 0.096\n",
      "Train Loss: 15.2732519944\n",
      "Test Loss: 10.7433605221\n",
      "---------------------------\n",
      "Turn 33\n",
      "w: [ 0.01584908  0.03273664  0.04899329  0.06544078  0.15433801  0.09019022\n",
      "  0.05303224  0.66670701  0.3614193   0.04642474  0.01682314  0.04065219\n",
      " -0.02827784  0.01033434]\n",
      "b: 0.097\n",
      "Train Loss: 15.2197697423\n",
      "Test Loss: 10.7057481925\n",
      "---------------------------\n",
      "Turn 34\n",
      "w: [ 0.01593324  0.03279178  0.04936747  0.06587534  0.15499136  0.09067503\n",
      "  0.05332486  0.6733403   0.35895789  0.04674399  0.01590632  0.04121154\n",
      " -0.02858806  0.0107918 ]\n",
      "b: 0.096\n",
      "Train Loss: 15.1669895593\n",
      "Test Loss: 10.6697992371\n",
      "---------------------------\n",
      "Turn 35\n",
      "w: [ 0.0160173   0.03284687  0.04974128  0.06630946  0.15564406  0.09115936\n",
      "  0.05361718  0.67996696  0.35649893  0.04706292  0.01499041  0.04177033\n",
      " -0.02889798  0.0112488 ]\n",
      "b: 0.095\n",
      "Train Loss: 15.1145463517\n",
      "Test Loss: 10.6349671357\n",
      "---------------------------\n",
      "Turn 36\n",
      "w: [ 0.01600128  0.03292545  0.05020311  0.06674315  0.15628842  0.0916682\n",
      "  0.05399869  0.68648699  0.35394243  0.04745168  0.01417542  0.04232856\n",
      " -0.02912618  0.01179595]\n",
      "b: 0.093\n",
      "Train Loss: 15.0631432199\n",
      "Test Loss: 10.6009940757\n",
      "---------------------------\n",
      "Turn 37\n",
      "w: [ 0.01608528  0.03295908  0.05059305  0.06707641  0.15701675  0.09215153\n",
      "  0.05429034  0.69290051  0.35128849  0.04774005  0.01346124  0.04288623\n",
      " -0.02944215  0.01224255]\n",
      "b: 0.092\n",
      "Train Loss: 15.0126238213\n",
      "Test Loss: 10.5670009098\n",
      "---------------------------\n",
      "Turn 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [ 0.0160692   0.03305834  0.05103975  0.06740933  0.15773665  0.09265938\n",
      "  0.05467468  0.69920761  0.3485372   0.04811917  0.01284778  0.04344334\n",
      " -0.02965781  0.0127887 ]\n",
      "b: 0.09\n",
      "Train Loss: 14.9626204595\n",
      "Test Loss: 10.534237727\n",
      "---------------------------\n",
      "Turn 39\n",
      "w: [ 0.01615313  0.03308056  0.05139135  0.06764192  0.15852507  0.09321672\n",
      "  0.0549639   0.7054084   0.34568866  0.04839792  0.01233493  0.0439999\n",
      " -0.02996005  0.01323431]\n",
      "b: 0.089\n",
      "Train Loss: 14.9143001175\n",
      "Test Loss: 10.5014355872\n",
      "---------------------------\n",
      "Turn 40\n",
      "w: [ 0.01613698  0.03311178  0.05179857  0.06787428  0.1594127   0.0937735\n",
      "  0.05532416  0.71130299  0.34254297  0.04874057  0.0119226   0.0445559\n",
      " -0.03015519  0.01377739]\n",
      "b: 0.087\n",
      "Train Loss: 14.8669037448\n",
      "Test Loss: 10.4692291857\n",
      "---------------------------\n",
      "Turn 41\n",
      "w: [ 0.01612084  0.03314296  0.05220537  0.06810641  0.16029944  0.09432973\n",
      "  0.05568407  0.71719169  0.33940043  0.04908287  0.01151068  0.04511134\n",
      " -0.03035014  0.01431993]\n",
      "b: 0.085\n",
      "Train Loss: 14.8196013178\n",
      "Test Loss: 10.4371025401\n",
      "---------------------------\n",
      "Turn 42\n",
      "w: [ 0.01610472  0.03317412  0.05261178  0.0683383   0.16118529  0.0948854\n",
      "  0.05604361  0.7230745   0.33626103  0.04942483  0.01109917  0.04566623\n",
      " -0.03054489  0.01486193]\n",
      "b: 0.083\n",
      "Train Loss: 14.7726108139\n",
      "Test Loss: 10.4050556213\n",
      "---------------------------\n",
      "Turn 43\n",
      "w: [ 0.01618861  0.03313584  0.05292195  0.06846996  0.16215488  0.09551551\n",
      "  0.05630367  0.72885142  0.33302477  0.04966645  0.01058807  0.04622057\n",
      " -0.03081544  0.01530339]\n",
      "b: 0.082\n",
      "Train Loss: 14.7262659046\n",
      "Test Loss: 10.3726707224\n",
      "---------------------------\n",
      "Turn 44\n",
      "w: [ 0.01627242  0.03309759  0.05323181  0.06860149  0.16312349  0.096145\n",
      "  0.05656347  0.73462257  0.32979174  0.04990783  0.01007748  0.04677435\n",
      " -0.03108573  0.0157444 ]\n",
      "b: 0.081\n",
      "Train Loss: 14.6800134388\n",
      "Test Loss: 10.3404705436\n",
      "---------------------------\n",
      "Turn 45\n",
      "w: [ 0.01635615  0.03305938  0.05354137  0.06873289  0.16409113  0.09677385\n",
      "  0.05682302  0.74038795  0.32656195  0.05014897  0.0095674   0.04732757\n",
      " -0.03135574  0.01618498]\n",
      "b: 0.08\n",
      "Train Loss: 14.6338532317\n",
      "Test Loss: 10.308369499\n",
      "---------------------------\n",
      "Turn 46\n",
      "w: [ 0.0164398   0.03302121  0.05385061  0.06886416  0.16505781  0.09740208\n",
      "  0.0570823   0.74614756  0.32333539  0.05038986  0.00905783  0.04788024\n",
      " -0.03162548  0.01662511]\n",
      "b: 0.079\n",
      "Train Loss: 14.5877850991\n",
      "Test Loss: 10.2764780072\n",
      "---------------------------\n",
      "Turn 47\n",
      "w: [ 0.01652336  0.03298307  0.05415955  0.06899529  0.16602352  0.09802968\n",
      "  0.05734132  0.75190141  0.32011205  0.05063052  0.00854878  0.04843236\n",
      " -0.03189496  0.01706481]\n",
      "b: 0.078\n",
      "Train Loss: 14.5418143623\n",
      "Test Loss: 10.2448451291\n",
      "---------------------------\n",
      "Turn 48\n",
      "w: [ 0.01650683  0.03301165  0.05454853  0.0691263   0.16698058  0.09868165\n",
      "  0.05768429  0.75754951  0.31679194  0.05095302  0.00814023  0.04898393\n",
      " -0.03208256  0.01760286]\n",
      "b: 0.076\n",
      "Train Loss: 14.4962364851\n",
      "Test Loss: 10.2142334779\n",
      "---------------------------\n",
      "Turn 49\n",
      "w: [ 0.01679033  0.03287353  0.05468445  0.06925717  0.16795975  0.09935796\n",
      "  0.05781114  0.76329196  0.31357515  0.05100804  0.00783209  0.04953495\n",
      " -0.03252038  0.01784158]\n",
      "b: 0.077\n",
      "Train Loss: 14.4513374731\n",
      "Test Loss: 10.1821764613\n",
      "---------------------------\n",
      "Iteration End\n",
      "w: [ 0.01697354  0.03291524  0.0550113   0.06938791  0.16891487  0.10010861\n",
      "  0.05819778  0.76872867  0.31006157  0.05132718  0.00762425  0.05008541\n",
      " -0.03272936  0.01837882]\n",
      "b: 0.075\n",
      "Train Loss: 14.4064919084\n",
      "Test Loss: 10.1517806029\n",
      "---------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSikfp0GglFI+7v8BJGQMKPJWdhwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5109437518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = SVM(turns = 50, learning_rate = 0.001, c = 0.1)\n",
    "clf.fit(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
